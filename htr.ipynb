{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from itertools import groupby\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \"\n",
    "max_str_len = 19  \n",
    "num_of_characters = len(alphabets) + 1  \n",
    "num_of_timestamps = 64  \n",
    "default_path = \"IAM/img/\"\n",
    "batch_size = 512\n",
    "\n",
    "def label_to_num(txt):\n",
    "    dig_lst = []\n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(alphabets.index(char))\n",
    "        except:\n",
    "            pass\n",
    "    return pad_sequences([dig_lst], maxlen=max_str_len, padding='post', value=len(alphabets))[0]\n",
    "\n",
    "def ctc_decoder(predictions):\n",
    "    text_list = []   \n",
    "    pred_indcies = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    for i in range(pred_indcies.shape[0]):\n",
    "        ans = \"\"\n",
    "        merged_list = [k for k,_ in groupby(pred_indcies[i])]\n",
    "        for p in merged_list:\n",
    "            if p != len(alphabets):\n",
    "                ans += alphabets[int(p)]     \n",
    "        text_list.append(ans)    \n",
    "    return text_list\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  \n",
    "            break\n",
    "        else:\n",
    "            ret += alphabets[ch]\n",
    "    return ret\n",
    "\n",
    "def process_single_sample(img_path, label):\n",
    "    try:\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.io.decode_png(img, channels=1)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img = tf.image.resize(img, [32, 128])\n",
    "        return {\"image\": img, \"label\": label}\n",
    "    except:\n",
    "        print(\"file not found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103785, 2)\n",
      "(11532, 2)\n",
      "(115317, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('data.xlsx')\n",
    "data = pd.DataFrame(data, columns = ['Fpath','Identify']).astype(str)\n",
    "data.dropna(axis=0, inplace=True)\n",
    " \n",
    "train = data.sample(frac=0.9, random_state=42)\n",
    "unique_train = train['Fpath'].unique()\n",
    "valid = data.drop(train.index)\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '#', '&', '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "[' ', '!', '#', '&', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "train = train[0:80000]\n",
    "valid = valid[0:8000]\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "valid.reset_index(inplace=True, drop=True)\n",
    "\n",
    "vocab = set(\"\".join(map(str, valid['Identify'])))\n",
    "print(sorted(vocab))\n",
    "vocab = set(\"\".join(map(str, train['Identify'])))\n",
    "print(sorted(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "train_size = 80000\n",
    "valid_size = 8000\n",
    "print(valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "valid_x = []\n",
    "\n",
    "for i in range(valid_size):\n",
    "    path= valid.loc[i, 'Fpath']\n",
    "    img_dir = default_path + path    \n",
    "    valid_x.append(img_dir)\n",
    "\n",
    "for i in range(train_size):\n",
    "    path= train.loc[i, 'Fpath']\n",
    "    img_dir = default_path + path\n",
    "    train_x.append(img_dir)\n",
    "\n",
    "valid_y = []\n",
    "for i in range(valid_size):\n",
    "    string = valid.loc[i, 'Identify']\n",
    "    valid_y.append(label_to_num(string))\n",
    "\n",
    "train_y = []\n",
    "for i in range(train_size):\n",
    "    string = train.loc[i, 'Identify']\n",
    "    train_y.append(label_to_num(string))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
    "valid_dataset = (\n",
    "    valid_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 10, 28, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,\n",
       "       63, 63])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, name=None):\n",
    "\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = K.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(32, 128, 1), name='image')\n",
    "labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', activation='selu')(input_data)\n",
    "inner = MaxPool2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', activation='selu')(inner)\n",
    "inner = MaxPool2D(pool_size=(2, 2), name='max2')(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', activation='selu')(inner)\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv4', activation='selu')(inner)\n",
    "\n",
    "inner = Conv2D(512, (3, 3), padding='same', name='conv5', activation='selu')(inner)\n",
    "inner = Conv2D(512, (3, 3), padding='same', name='conv6', activation='selu')(inner)\n",
    "inner = Dropout(0.2)(inner)\n",
    "\n",
    "inner = Conv2D(512, (3, 3), padding='same', name='conv7', activation='selu')(inner)\n",
    "inner = Conv2D(512, (3, 3), padding='same', name='conv8', activation='selu')(inner)\n",
    "inner = MaxPool2D(pool_size=(2, 1), name='max8')(inner)\n",
    "\n",
    "inner = Conv2D(256, (3, 3), padding='same', name='conv9',  activation='selu')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Dropout(0.2)(inner)\n",
    "\n",
    "inner = Conv2D(256, (3, 3), padding='same', name='conv10', activation='selu')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = MaxPool2D(pool_size=(2, 1), name='max10')(inner)\n",
    "inner = Dropout(0.2)(inner)\n",
    "\n",
    "inner = Conv2D(64, (2,2), name='conv11', activation='selu')(inner)\n",
    "inner = Dropout(0.2)(inner)\n",
    "\n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(inner)\n",
    "\n",
    "inner = Bidirectional(LSTM(128, return_sequences=True), name='lstm1')(squeezed)\n",
    "inner = Bidirectional(LSTM(512, return_sequences=True), name='lstm2')(inner)\n",
    "inner = Bidirectional(LSTM(512, return_sequences=True), name='lstm3')(inner)\n",
    "inner = Bidirectional(LSTM(512, return_sequences=True), name='lstm4')(inner)\n",
    "inner = Bidirectional(LSTM(128, return_sequences=True), name='lstm5')(inner)\n",
    "\n",
    "dense_= Dense(128,activation = 'relu')(inner)\n",
    "y_pred = Dense(num_of_characters,activation = 'softmax', name='dense2')(dense_)\n",
    "output = CTCLayer(name=\"ctc_loss\",)(labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 32, 128, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 32, 128, 32)  320         ['image[0][0]']                  \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 16, 64, 32)   0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 16, 64, 64)   18496       ['max1[0][0]']                   \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 8, 32, 64)    0           ['conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 8, 32, 128)   73856       ['max2[0][0]']                   \n",
      "                                                                                                  \n",
      " conv4 (Conv2D)                 (None, 8, 32, 128)   147584      ['conv3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv5 (Conv2D)                 (None, 8, 32, 512)   590336      ['conv4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv6 (Conv2D)                 (None, 8, 32, 512)   2359808     ['conv5[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 32, 512)   0           ['conv6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv7 (Conv2D)                 (None, 8, 32, 512)   2359808     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv8 (Conv2D)                 (None, 8, 32, 512)   2359808     ['conv7[0][0]']                  \n",
      "                                                                                                  \n",
      " max8 (MaxPooling2D)            (None, 4, 32, 512)   0           ['conv8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv9 (Conv2D)                 (None, 4, 32, 256)   1179904     ['max8[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 4, 32, 256)  1024        ['conv9[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 32, 256)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv10 (Conv2D)                (None, 4, 32, 256)   590080      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 4, 32, 256)  1024        ['conv10[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max10 (MaxPooling2D)           (None, 2, 32, 256)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 2, 32, 256)   0           ['max10[0][0]']                  \n",
      "                                                                                                  \n",
      " conv11 (Conv2D)                (None, 1, 31, 64)    65600       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 1, 31, 64)    0           ['conv11[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 31, 64)       0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " lstm1 (Bidirectional)          (None, 31, 256)      197632      ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm2 (Bidirectional)          (None, 31, 1024)     3149824     ['lstm1[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm3 (Bidirectional)          (None, 31, 1024)     6295552     ['lstm2[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm4 (Bidirectional)          (None, 31, 1024)     6295552     ['lstm3[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm5 (Bidirectional)          (None, 31, 256)      1180672     ['lstm4[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 31, 128)      32896       ['lstm5[0][0]']                  \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 31, 64)       8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 31, 64)       0           ['label[0][0]',                  \n",
      "                                                                  'dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,908,032\n",
      "Trainable params: 26,907,008\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "train_model = Model(inputs=[input_data, labels], outputs=output)\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0),\n",
    "                    metrics=[tf.keras.metrics.Accuracy()])\n",
    "\n",
    "filepath = \"best_model.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor= 'val_loss',\n",
    "                             verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='auto', patience=15)\n",
    "\n",
    "callbacks_list = [checkpoint, earlyStopping]\n",
    "\n",
    "history = train_model.fit(train_dataset,\n",
    "                          epochs=1,\n",
    "                          validation_data=valid_dataset,\n",
    "                          verbose = 1,\n",
    "                          shuffle=True,   \n",
    "                          callbacks=callbacks_list)\n",
    "\n",
    "train_model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 19s 1s/step\n",
      "16/16 [==============================] - 21s 1s/step\n",
      "16/16 [==============================] - 22s 1s/step\n",
      "16/16 [==============================] - 20s 1s/step\n",
      "16/16 [==============================] - 19s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 17s 1s/step\n",
      "16/16 [==============================] - 17s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "16/16 [==============================] - 18s 1s/step\n",
      "10/10 [==============================] - 11s 1s/step\n",
      "Correct characters predicted : 81.32%\n",
      "Correct words predicted      : 68.17%\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "for batch in valid_dataset.as_numpy_iterator():\n",
    "    preds = model.predict(batch)\n",
    "    prediction.extend(ctc_decoder(preds))\n",
    "\n",
    "y_true = valid.loc[0:valid_size, 'Identify']\n",
    "correct_char = 0\n",
    "total_char = 0\n",
    "correct = 0\n",
    "for i in range(valid_size):\n",
    "    pr = prediction[i]\n",
    "    tr = y_true[i]\n",
    "    total_char += len(tr)\n",
    "\n",
    "    for j in range(min(len(tr), len(pr))):\n",
    "        if tr[j] == pr[j]:\n",
    "            correct_char += 1\n",
    "    if pr == tr:\n",
    "        correct += 1\n",
    "\n",
    "print('Correct characters predicted : %.2f%%' % (correct_char * 100 / total_char))\n",
    "print('Correct words predicted      : %.2f%%' % (correct * 100 / valid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n"
     ]
    }
   ],
   "source": [
    "img = process_single_sample(\"would.jpg\",\"would\")\n",
    "pred = model.predict(np.asarray([img[\"image\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_decoder(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
